@article{abadiDesignImplementationModern2012,
  title = {The {{Design}} and {{Implementation}} of {{Modern Column-Oriented Database Systems}}},
  author = {Abadi, Daniel and Peter, Boncz and Stavros, Harizopoulos and Stratos, Idreos and Samuel, Madden},
  date = {2012},
  journaltitle = {Foundations and Trends® in Databases},
  shortjournal = {FNT in Databases},
  volume = {5},
  number = {3},
  pages = {197--280},
  issn = {1931-7883, 1931-7891},
  doi = {10.1561/1900000024},
  url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-databases/DBS-024},
  urldate = {2023-12-26},
  langid = {english},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\columnstoresfntdbs.pdf}
}

@article{bonczBreakingMemoryWall2008a,
  title = {Breaking the {{Memory Wall}} in {{MonetDB}}},
  author = {Boncz, Peter and Kersten, Martin and Manegold, Stefan},
  date = {2008-12},
  journaltitle = {Commun. ACM},
  volume = {51},
  number = {12},
  pages = {77--85},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0001-0782},
  doi = {10.1145/1409360.1409380},
  url = {https://doi.org/10.1145/1409360.1409380},
  urldate = {2023-12-31},
  abstract = {In the past decades, advances in speed of commodity CPUs have far outpaced advances in RAM latency. Main-memory access has therefore become a performance bottleneck for many computer applications; a phenomenon that is widely known as the "memory wall." In this paper, we report how research around the MonetDB database system has led to a redesign of database architecture in order to take advantage of modern hardware, and in particular to avoid hitting the memory wall. This encompasses (i) a redesign of the query execution model to better exploit pipelined CPU architectures and CPU instruction caches; (ii) the use of columnar rather than row-wise data storage to better exploit CPU data caches; (iii) the design of new cache-conscious query processing algorithms; and (iv) the design and automatic calibration of memory cost models to choose and tune these cache-conscious algorithms in the query optimizer.},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\BreakingTheMemoryWall.pdf}
}

@unpublished{bonczDataSystemsResearch2022,
  title = {Data {{Systems Research}} at {{CWI}}},
  author = {Boncz, Peter},
  date = {2022-06-01},
  url = {https://docs.google.com/presentation/d/1lqf2ckpSiVc_7EgPafoSqcmzLVZvDHna_cACx4vWTSs/edit#slide=id.g12071bc6c72_0_0},
  urldate = {2023-12-31},
  eventtitle = {Siks {{Day}} 2022},
  langid = {english},
  venue = {{Utrecht, Netherlands}},
  file = {C\:\\Users\\henri\\Documents\\WS23_24\\LDE\\References\\Data Systems Research at CWI (2023).pdf;C\:\\Users\\henri\\Documents\\WS23_24\\LDE\\References\\Data Systems Research at CWI (2023).pptx}
}

@inproceedings{bonczDrillBenchmark1998a,
  title = {The {{Drill Down Benchmark}}},
  booktitle = {Proceedings of the 24rd {{International Conference}} on {{Very Large Data Bases}}},
  author = {Boncz, Peter and Rühl, Tim and Kwakkel, Fred},
  date = {1998},
  series = {{{VLDB}} '98},
  pages = {628--632},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  location = {{San Francisco, CA, USA}},
  url = {https://www.vldb.org/conf/1998/p628.pdf},
  urldate = {2023-12-26},
  isbn = {1-55860-566-5},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\DrillDownBenchmark.pdf}
}

@article{bonczMILPrimitivesQuerying1999,
  title = {{{MIL Primitives}} for {{Querying}} a {{Fragmented World}}},
  author = {Boncz, Peter and Kersten, Martin},
  date = {1999-10},
  journaltitle = {The VLDB Journal},
  volume = {8},
  number = {2},
  pages = {101--119},
  publisher = {{Springer-Verlag}},
  location = {{Berlin, Heidelberg}},
  issn = {1066-8888},
  doi = {10.1007/s007780050076},
  url = {https://doi.org/10.1007/s007780050076},
  abstract = {In query-intensive database application areas, like decision support and data mining, systems that use vertical fragmentation have a significant performance advantage. In order to support relational or object oriented applications on top of such a fragmented data model, a flexible yet powerful intermediate language is needed. This problem has been successfully tackled in Monet, a modern extensible database kernel developed by our group. We focus on the design choices made in the Monet interpreter language (MIL), its algebraic query language, and outline how its concept of tactical optimization enhances and simplifies the optimization of complex queries. Finally, we summarize the experience gained in Monet by creating a highly efficient implementation of MIL.},
  keywords = {Database systems,Main-memory techniques,Query languages,Query optimization,Vertical fragmentation},
  file = {C:\Users\henri\Documents\WS23_24\LDE\MIL primitives for querying a fragmented world.pdf}
}

@inproceedings{bonczMonetDBX100HyperPipelining2005,
  title = {{{MonetDB}}/{{X100}}: {{Hyper-Pipelining Query Execution}}},
  booktitle = {Proceedings of the 2005 {{CIDR Conference}}},
  author = {Boncz, Peter and Zukowski, Marcin and Nes, Niels},
  date = {2005},
  pages = {225--237},
  location = {{Asilomar, USA}},
  url = {https://ir.cwi.nl/pub/16497/16497B.pdf},
  urldate = {2023-12-31},
  eventtitle = {Conference on {{Innovative Data Systems Research}}},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\MonetDBX100.pdf}
}

@article{coleOptimizationDynamicQuery1994,
  title = {Optimization of {{Dynamic Query Evaluation Plans}}},
  author = {Cole, Richard L. and Graefe, Goetz},
  date = {1994-05},
  journaltitle = {SIGMOD Rec.},
  volume = {23},
  number = {2},
  pages = {150--160},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0163-5808},
  doi = {10.1145/191843.191872},
  url = {https://doi.org/10.1145/191843.191872},
  urldate = {2024-01-05},
  abstract = {Traditional query optimizers assume accurate knowledge of run-time parameters such as selectivities and resource availability during plan optimization, i.e., at compile time. In reality, however, this assumption is often not justified. Therefore, the “static” plans produced by traditional optimizers may not be optimal for many of their actual run-time invocations. Instead, we propose a novel optimization model that assigns the bulk of the optimization effort to compile-time and delays carefully selected optimization decisions until run-time. Our previous work defined the run-time primitives, “dynamic plans” using “choose-plan” operators, for executing such delayed decisions, but did not solve the problem of constructing dynamic plans at compile-time. The present paper introduces techniques that solve this problem. Experience with a working prototype optimizer demonstrates (i) that the additional optimization and start-up overhead of dynamic plans compared to static plans is dominated by their advantage at run-time, (ii) that dynamic plans are as robust as the “brute-force” remedy of run-time optimization, i.e., dynamic plans maintain their optimality even if parameters change between compile-time and run-time, and (iii) that the start-up overhead of dynamic plans is significantly less than the time required for complete optimization at run-time. In other words, our proposed techniques are superior to both techniques considered to-date, namely compile-time optimization into a single static plan as well as run-time optimization. Finally, we believe that the concepts and technology described can be transferred to commercial query optimizers in order to improve the performance of embedded queries with host variables in the query predicate and to adapt to run-time system loads unpredictable at compile time.},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\OptimizationOfDynamicQuery.pdf}
}

@article{copelandDecompositionStorageModel1985,
  title = {A {{Decomposition Storage Model}}},
  author = {Copeland, George and Khoshafian, Setrag},
  date = {1985-05},
  journaltitle = {SIGMOD Rec.},
  volume = {14},
  number = {4},
  pages = {268--279},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0163-5808},
  doi = {10.1145/971699.318923},
  url = {https://doi.org/10.1145/971699.318923},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\ADecompositionStorageModel.pdf}
}

@inproceedings{cornacchiaCaseStudyArray2004a,
  title = {A {{Case Study}} on {{Array Query Optimisation}}},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Computer Vision Meets Databases}}},
  author = {Cornacchia, Roberto and family=Ballegooij, given=Alex, prefix=van, useprefix=true and family=Vries, given=Arjen, prefix=de, useprefix=true},
  date = {2004},
  series = {{{CVDB}} '04},
  pages = {3--10},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1039470.1039476},
  url = {https://doi.org/10.1145/1039470.1039476},
  urldate = {2023-12-26},
  abstract = {The development of applications involving multi-dimensional data sets on top of a RDBMS raises several difficulties that are not directly related to the scientific problem being addressed. In particular, an additional effort is needed to solve the mismatch existing between the array-based data model typical of such computations and the set-based data model provided by the RDMBS. The RAM (Relational Array Mapping) system fills this gap, silently providing a mapping layer between the two data models. As expected though, a naive implementation of such an automatic translation cannot compete with the efficiency of queries written by an experienced programmer. In order to make RAM a valid alternative to expensive and time-consuming hand-written solutions, this performance gap should be reduced. We study a real-world application aimed at the ranking of multimedia collections to assess the impact of different implementation strategies. The result of this study provides an illustrative outlook for the development of generally applicable optimisation techniques.},
  isbn = {1-58113-917-9},
  venue = {Paris, France}
}

@article{farberSAPHANADatabase2012,
  title = {The {{SAP HANA Database}}–{{An Architecture Overview}}.},
  author = {Färber, Franz and May, Norman and Lehner, Wolfgang and Große, Philipp and Müller, Ingo and Rauhe, Hannes and Dees, Jonathan},
  date = {2012},
  journaltitle = {IEEE Data Eng. Bull.},
  volume = {35},
  number = {1},
  pages = {28--33},
  publisher = {{Citeseer}},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=afda6470dd16dc0a865dbb6fc291e5806132379b},
  urldate = {2023-12-31},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\SAPHana.pdf}
}

@inproceedings{gawadeAdaptiveQueryParallelization2016,
  title = {Adaptive Query Parallelization in Multi-Core Column Stores},
  booktitle = {International {{Conference}} on {{Extending Database Technology}}},
  author = {Gawade, Mrunal and Kersten, Martin},
  date = {2016-03},
  url = {https://api.semanticscholar.org/CorpusID:642159}
}

@inproceedings{graefeDynamicQueryEvaluation1989,
  title = {Dynamic {{Query Evaluation Plans}}},
  booktitle = {Proceedings of the 1989 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Graefe, Goetz and Ward, K.},
  date = {1989},
  series = {{{SIGMOD}} '89},
  pages = {358--366},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/67544.66960},
  url = {https://doi.org/10.1145/67544.66960},
  abstract = {In most database systems, a query embedded in a program written in a conventional programming language is optimized when the program is compiled. The query optimizer must make assumptions about the values of the program variables that appear as constants in the query, the resources that can be committed to query evaluation, and the data in the database. The optimality of the resulting query evaluation plan depends on the validity of these assumptions. If a query evaluation plan is used repeatedly over an extended period of time, it is important to determine when reoptimization is necessary. Our work aims at developing criteria when reoptimization is required, how these criteria can be implemented efficiently, and how reoptimization can be avoided by using a new technique called dynamic query evaluation plans. We experimentally demonstrate the need for dynamic plans and outline modifications to the EXODUS optimizer generator required for creating dynamic query evaluation plans.},
  isbn = {0-89791-317-5},
  venue = {Portland, Oregon, USA}
}

@article{graefeDynamicQueryEvaluation1989c,
  title = {Dynamic {{Query Evaluation Plans}}},
  author = {Graefe, G. and Ward, K.},
  date = {1989-06},
  journaltitle = {SIGMOD Rec.},
  volume = {18},
  number = {2},
  pages = {358--366},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0163-5808},
  doi = {10.1145/66926.66960},
  url = {https://doi.org/10.1145/66926.66960},
  urldate = {2024-01-05},
  abstract = {In most database systems, a query embedded in a program written in a conventional programming language is optimized when the program is compiled. The query optimizer must make assumptions about the values of the program variables that appear as constants in the query, the resources that can be committed to query evaluation, and the data in the database. The optimality of the resulting query evaluation plan depends on the validity of these assumptions. If a query evaluation plan is used repeatedly over an extended period of time, it is important to determine when reoptimization is necessary. Our work aims at developing criteria when reoptimization is required, how these criteria can be implemented efficiently, and how reoptimization can be avoided by using a new technique called dynamic query evaluation plans. We experimentally demonstrate the need for dynamic plans and outline modifications to the EXODUS optimizer generator required for creating dynamic query evaluation plans.},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\DynamicQueryEvaluationPlans.pdf}
}

@article{graefeQueryEvaluationTechniques1993,
  title = {Query {{Evaluation Techniques}} for {{Large Databases}}},
  author = {Graefe, Goetz},
  date = {1993-06},
  journaltitle = {ACM Comput. Surv.},
  volume = {25},
  number = {2},
  pages = {73--169},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0360-0300},
  doi = {10.1145/152610.152611},
  url = {https://doi.org/10.1145/152610.152611},
  urldate = {2023-12-31},
  abstract = {Database management systems will continue to manage large data volumes. Thus, efficient algorithms for accessing and manipulating large sets and sequences will be required to provide acceptable performance. The advent of object-oriented and extensible database systems will not solve this problem. On the contrary, modern data models exacerbate the problem: In order to manipulate large sets of complex objects as efficiently as today's database systems manipulate simple records, query-processing algorithms and software will become more complex, and a solid understanding of algorithm and architectural issues is essential for the designer of database management software.This survey provides a foundation for the design and implementation of query execution facilities in new database management systems. It describes a wide array of practical query evaluation techniques for both relational and postrelational database systems, including iterative execution of complex query evaluation plans, the duality of sort- and hash-based set-matching algorithms, types of parallel query execution and their implementation, and special operators for emerging database application domains.},
  keywords = {complex query evaluation plans,dynamic query evaluation plans,extensible database systems,iterators,object-oriented database systems,operator model of parallelization,parallel algorithms,relational database systems,set-matching algorithms,sort-hash duality}
}

@article{graefeQueryEvaluationTechniques1993a,
  title = {Query {{Evaluation Techniques}} for {{Large Databases}}},
  author = {Graefe, Goetz},
  date = {1993-06},
  journaltitle = {ACM Comput. Surv.},
  volume = {25},
  number = {2},
  pages = {73--169},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0360-0300},
  doi = {10.1145/152610.152611},
  url = {https://doi.org/10.1145/152610.152611},
  urldate = {2024-01-05},
  abstract = {Database management systems will continue to manage large data volumes. Thus, efficient algorithms for accessing and manipulating large sets and sequences will be required to provide acceptable performance. The advent of object-oriented and extensible database systems will not solve this problem. On the contrary, modern data models exacerbate the problem: In order to manipulate large sets of complex objects as efficiently as today's database systems manipulate simple records, query-processing algorithms and software will become more complex, and a solid understanding of algorithm and architectural issues is essential for the designer of database management software.This survey provides a foundation for the design and implementation of query execution facilities in new database management systems. It describes a wide array of practical query evaluation techniques for both relational and postrelational database systems, including iterative execution of complex query evaluation plans, the duality of sort- and hash-based set-matching algorithms, types of parallel query execution and their implementation, and special operators for emerging database application domains.},
  keywords = {complex query evaluation plans,dynamic query evaluation plans,extensible database systems,iterators,object-oriented database systems,operator model of parallelization,parallel algorithms,relational database systems,set-matching algorithms,sort-hash duality},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\QueryEvaluationTechniques.pdf}
}

@online{intelrAccelerateFastMath,
  title = {Accelerate {{Fast Math}} with {{Intel}}® {{oneAPI Math Kernel Library}}},
  author = {{Intel®}},
  url = {https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html},
  urldate = {2024-03-01},
  abstract = {Use this library of math routines for compute-intensive tasks: linear algebra, FFT, RNG. Optimized for high-performance computing and data science.},
  langid = {english},
  organization = {{Intel.com}},
  file = {C:\Users\henri\Zotero\storage\CUJZVRHA\onemkl.html}
}

@article{ivanovaParallelProcessingVery2017,
  title = {Parallel Processing of Very Large Databases Using Distributed Column Indexes},
  author = {Ivanova, E. V. and Sokolinsky, L. B.},
  date = {2017-05-01},
  journaltitle = {Programming and Computer Software},
  shortjournal = {Programming and Computer Software},
  volume = {43},
  number = {3},
  pages = {131--144},
  issn = {1608-3261},
  doi = {10.1134/S0361768817030069},
  url = {https://doi.org/10.1134/S0361768817030069},
  urldate = {2024-01-04},
  abstract = {The development and investigation of efficient methods of parallel processing of very large databases using the columnar data representation designed for computer cluster is discussed. An approach that combines the advantages of relational and column-oriented DBMSs is proposed. A new type of distributed column indexes fragmented based on the domain-interval principle is introduced. The column indexes are auxiliary structures that are constantly stored in the distributed main memory of a computer cluster. To match the elements of a column index to the tuples of the original relation, surrogate keys are used. Resource hungry relational operations are performed on the corresponding column indexes rather than on the original relations of the database. As a result, a precomputation table is obtained. Using this table, the DBMS reconstructs the resulting relation. For basic relational operations on column indexes, methods for their parallel decomposition that do not require massive data exchanges between the processor nodes are proposed. This approach improves the class OLAP query performance by hundreds of times.},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\ParallelProcessing.pdf}
}

@inproceedings{klyuchikovHybridMaterializationDiskBased2024,
  title = {Hybrid {{Materialization}} in a {{Disk-Based Column-Store}}},
  booktitle = {Proceedings of the 7th {{Joint International Conference}} on {{Data Science}} \& {{Management}} of {{Data}} (11th {{ACM IKDD CODS}} and 29th {{COMAD}})},
  author = {Klyuchikov, Evgeniy and Polyntsov, Michael and Chizhov, Anton and Mikhailova, Elena and Chernishev, George},
  date = {2024},
  series = {{{CODS-COMAD}} '24},
  pages = {164--172},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3632410.3632422},
  url = {https://doi.org/10.1145/3632410.3632422},
  urldate = {2024-01-04},
  abstract = {In column-oriented query processing, a materialization strategy determines when lightweight positions (row IDs) are translated into tuples. It is an important part of column-store architecture, since it defines the class of supported query plans, and, therefore, impacts overall system performance. In this paper, we continue investigating materialization strategies for a distributed disk-based column-store. We start by demonstrating cases of existing approaches fundamentally limiting resulting system performance. In order to address them, we propose a new model of hybrid materialization. The main feature of hybrid materialization is the ability to manipulate both positions and values at the same time. This way, the query engine can efficiently combine advantages of all the existing strategies and support a new class of query plans. Moreover, hybrid materialization enables the query engine to flexibly customize the materialization policy of individual attributes. We describe our vision of how hybrid materialization can be implemented in a columnar system. As an example, we use PosDB\&nbsp;— a distributed, disk-based column-store. We present necessary data structures, the internals of a hybrid operator, and describe the algebra of such operators. Based on this implementation, we evaluate performance of late, ultra-late, and hybrid materialization strategies in several scenarios based on TPC-H queries. Our experiments demonstrate that hybrid materialization is almost two times faster than its counterparts, while providing a more flexible query model.},
  isbn = {9798400716348},
  keywords = {Analytic workloads,Column-stores,Databases,Hybrid materialization,Late Materialization,Query engine,Query processing},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\hybridMaterializationInADiskBasedColumnStore.pdf}
}

@inproceedings{manegoldCacheConsciousRadixDeclusterProjections2004a,
  title = {Cache-{{Conscious Radix-Decluster Projections}}},
  booktitle = {Proceedings of the {{Thirtieth International Conference}} on {{Very Large Data Bases}} - {{Volume}} 30},
  author = {Manegold, Stefan and Boncz, Peter and Nes, Niels and Kersten, Martin},
  date = {2004},
  series = {{{VLDB}} '04},
  pages = {684--695},
  publisher = {{VLDB Endowment}},
  location = {{Toronto, Canada}},
  url = {https://ir.cwi.nl/pub/11117/11117B.pdf},
  urldate = {2024-01-04},
  abstract = {As CPUs become more powerful with Moore's law and memory latencies stay constant, the impact of the memory access performance bottleneck continues to grow on relational operators like join, which can exhibit random access on a memory region larger than the hardware caches. While cache-conscious variants for various relational algorithms have been described, previous work has mostly ignored (the cost of) projection columns. However, real-life joins almost always come with projections, such that proper projection column manipulation should be an integral part of any generic join algorithm. In this paper, we analyze cache-conscious hash-join algorithms including projections on two storage schemes: N-ary Storage Model (NSM) and Decomposition Storage Model (DSM). It turns out, that the strategy of first executing the join and only afterwards dealing with the projection columns (i.e., post-projection) on DSM, in combination with a new finely tunable algorithm called Radix-Decluster, outperforms all previously reported projection strategies. To make this result generally applicable, we also outline how DSM Radix-Decluster can be integrated in a NSM-based RDBMS using projection indices.},
  isbn = {0-12-088469-0},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\CacheConciousRadix.pdf}
}

@inproceedings{manegoldMultiQueryOptimizerMonet2000a,
  title = {A {{Multi-Query Optimizer}} for {{Monet}}},
  booktitle = {Advances in {{Databases}}},
  author = {Manegold, Stefan and Pellenkoft, Arjan and Kersten, Martin},
  editor = {Lings, Brian and Jeffery, Keith},
  date = {2000},
  pages = {36--50},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  url = {https://api.semanticscholar.org/CorpusID:13640968},
  urldate = {2023-12-26},
  abstract = {Database systems allow for concurrent use of several applications (and query interfaces). Each application generates an “optimal” plan—a sequence of low-level database operators—for accessing the database. The queries posed by users through the same application can be optimized together using traditional multi-query optimization techniques. However, the commonalities among queries of different applications are not exploited.},
  isbn = {978-3-540-45033-7},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\MultiQueryOptimizerForMonet.pdf}
}

@article{manegoldOptimizingMainmemoryJoin2002,
  title = {Optimizing Main-Memory Join on Modern Hardware},
  author = {Manegold, S. and Boncz, P. and Kersten, M.},
  date = {2002},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {14},
  number = {4},
  pages = {709--730},
  url = {https://ir.cwi.nl/pub/11143/11143B.pdf},
  urldate = {2024-01-04},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\OptimizingMainMemory.pdf}
}

@inproceedings{manegoldWhatHappensJoin2000a,
  title = {What {{Happens During}} a {{Join}}? {{Dissecting CPU}} and {{Memory Optimization Effects}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{Very Large Data Bases}}},
  author = {Manegold, Stefan and Boncz, Peter and Kersten, Martin},
  date = {2000},
  series = {{{VLDB}} '00},
  pages = {339--350},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  location = {{San Francisco, CA, USA}},
  url = {https://ir.cwi.nl/pub/11168/11168B.pdf},
  urldate = {2023-12-26},
  isbn = {1-55860-715-3},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\WhatHappensDuringAJoin.pdf}
}

@online{monetdbb.v.Us,
  title = {About {{Us}}},
  author = {{MonetDB B.V.}},
  url = {https://www.monetdb.org/about-us/},
  urldate = {2024-01-04},
  langid = {american},
  file = {C:\Users\henri\Zotero\storage\4C39QEQ2\about-us.html}
}

@unpublished{pavloLecture11Joins2022,
  title = {Lecture \#11: {{Joins Algorithms}} of 15-445/645 {{Database Systems}} ({{Fall}} 2022)},
  author = {Pavlo, Andy},
  date = {2022},
  location = {{Pittsburgh}},
  url = {https://15445.courses.cs.cmu.edu/fall2022/notes/11-joins.pdf},
  urldate = {2024-01-04},
  howpublished = {Lecture Notes},
  pagetotal = {4},
  file = {C:\Users\henri\Zotero\storage\6Q95KPFS\11-joins.pdf}
}

@inproceedings{raasveldtDuckDBEmbeddableAnalytical2019,
  title = {{{DuckDB}}: An {{Embeddable Analytical Database}}},
  shorttitle = {{{DuckDB}}},
  booktitle = {Proceedings of the 2019 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Raasveldt, Mark and Mühleisen, Hannes},
  date = {2019-06-25},
  pages = {1981--1984},
  publisher = {{ACM}},
  location = {{Amsterdam Netherlands}},
  doi = {10.1145/3299869.3320212},
  url = {https://dl.acm.org/doi/10.1145/3299869.3320212},
  urldate = {2023-12-31},
  eventtitle = {{{SIGMOD}}/{{PODS}} '19: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-5643-5},
  langid = {english},
  file = {C:\Users\henri\Zotero\storage\LVKR2H25\Raasveldt and Mühleisen - 2019 - DuckDB an Embeddable Analytical Database.pdf}
}

@inproceedings{richardcoleOptimizationDynamicQuery1994,
  title = {Optimization of {{Dynamic Query Evaluation Plans}}},
  booktitle = {Proceedings of the 1994 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {{Richard Cole} and Graefe, Goetz},
  date = {1994},
  series = {{{SIGMOD}} '94},
  pages = {150--160},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/191839.191872},
  url = {https://doi.org/10.1145/191839.191872},
  urldate = {2023-12-31},
  abstract = {Traditional query optimizers assume accurate knowledge of run-time parameters such as selectivities and resource availability during plan optimization, i.e., at compile time. In reality, however, this assumption is often not justified. Therefore, the “static” plans produced by traditional optimizers may not be optimal for many of their actual run-time invocations. Instead, we propose a novel optimization model that assigns the bulk of the optimization effort to compile-time and delays carefully selected optimization decisions until run-time. Our previous work defined the run-time primitives, “dynamic plans” using “choose-plan” operators, for executing such delayed decisions, but did not solve the problem of constructing dynamic plans at compile-time. The present paper introduces techniques that solve this problem. Experience with a working prototype optimizer demonstrates (i) that the additional optimization and start-up overhead of dynamic plans compared to static plans is dominated by their advantage at run-time, (ii) that dynamic plans are as robust as the “brute-force” remedy of run-time optimization, i.e., dynamic plans maintain their optimality even if parameters change between compile-time and run-time, and (iii) that the start-up overhead of dynamic plans is significantly less than the time required for complete optimization at run-time. In other words, our proposed techniques are superior to both techniques considered to-date, namely compile-time optimization into a single static plan as well as run-time optimization. Finally, we believe that the concepts and technology described can be transferred to commercial query optimizers in order to improve the performance of embedded queries with host variables in the query predicate and to adapt to run-time system loads unpredictable at compile time.},
  isbn = {0-89791-639-5},
  venue = {Minneapolis, Minnesota, USA}
}

@article{shapiroJoinProcessingDatabase1986,
  title = {Join {{Processing}} in {{Database Systems}} with {{Large Main Memories}}},
  author = {Shapiro, Leonard D.},
  date = {1986-08},
  journaltitle = {ACM Trans. Database Syst.},
  volume = {11},
  number = {3},
  pages = {239--264},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0362-5915},
  doi = {10.1145/6314.6315},
  url = {https://doi.org/10.1145/6314.6315},
  urldate = {2024-01-04},
  abstract = {We study algorithms for computing the equijoin of two relations in a system with a standard architecture hut with large amounts of main memory. Our algorithms are especially efficient when the main memory available is a significant fraction of the size of one of the relations to he joined; but they can be applied whenever there is memory equal to approximately the square root of the size of one relation. We present a new algorithm which is a hybrid of two hash-based algorithms and which dominates the other algorithms we present, including sort-merge. Even in a virtual memory environment, the hybrid algorithm dominates all the others we study.Finally, we describe how three popular tools to increase the efficiency of joins, namely filters, Babb arrays, and semijoins, can he grafted onto any of our algorithms.},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\JoinProcessingInSystemsWith.pdf}
}

@article{BLIS1,
   author      = {Field G. {V}an~{Z}ee and Robert A. {v}an~{d}e~{G}eijn},
   title       = {{BLIS}: A Framework for Rapidly Instantiating {BLAS} Functionality},
   journal     = {ACM Transactions on Mathematical Software},
   volume      = {41},
   number      = {3},
   pages       = {14:1--14:33},
   month       = {6},
   year        = {2015},
   issue_date  = {June 2015},
   url         = {https://doi.acm.org/10.1145/2764454},
}

@incollection{svenssonEmergingDatabaseSystems2010,
  title = {Emerging Database Systems in Support of Scientific Data},
  booktitle = {Scientific {{Data Management}}: {{Challenges}}, {{Technology}}, and {{Deployment}}},
  author = {Svensson, Per and Boncz, Peter and Ivanova, Milena and Kersten, Martin and Nes, Niels and Rotem, Doron},
  date = {2010-01},
  pages = {235--277},
  publisher = {{Chapman \& Hall/CRC, Taylor and Francis Group, LLC}},
  location = {{Boca Raton, FL}},
  url = {https://ir.cwi.nl/pub/14982/14982B.pdf},
  urldate = {2023-12-26},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\EmergingVertical.pdf}
}

@inproceedings{szalaySDSSSkyserverPublic2002,
  title = {The {{SDSS Skyserver}}: {{Public Access}} to the {{Sloan Digital Sky Server Data}}},
  booktitle = {Proceedings of the 2002 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Szalay, Alexander S. and Gray, Jim and Thakar, Ani R. and Kunszt, Peter Z. and Malik, Tanu and Raddick, Jordan and Stoughton, Christopher and {vandenBerg}, Jan},
  date = {2002},
  series = {{{SIGMOD}} '02},
  pages = {570--581},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/564691.564758},
  url = {https://doi.org/10.1145/564691.564758},
  abstract = {The SkyServer provides Internet access to the public Sloan Digital Sky Survey (SDSS) data for both astronomers and for science education. This paper describes the SkyServer goals and architecture. It also describes our experience operating the SkyServer on the Internet. The SDSS data is public and well-documented so it makes a good test platform for research on database algorithms and performance.},
  isbn = {1-58113-497-5},
  venue = {Madison, Wisconsin}
}

@dataset{transactionprocessingperformancecouncilTPCBenchmark1995,
  type = {Benchmark},
  title = {{{TPC Benchmark D}}},
  author = {Transaction Processing Performance Council},
  date = {1995},
  location = {{San Jose, California}},
  version = {1.2.3 edition}
}

@article{dongarra_blas,
author = {Dongarra, J. J. and Cruz, Jermey Du and Hammarling, Sven and Duff, I. S.},
title = {Algorithm 679: A set of level 3 basic linear algebra subprograms: model implementation and test programs},
year = {1990},
issue_date = {March 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/77626.77627},
doi = {10.1145/77626.77627},
abstract = {This paper describes a model implementation and test software for the Level 3 Basic Linear Algebra Subprograms (Level3 BLAS). The Level3 BLAS are targeted at matrix-matrix operations with the aim of providing more efficient, but portable, implementations of algorithms on high-performance computers. The model implementation provides a portable set of Fortran 77 Level 3 BLAS for machines where specialized implementations do not exist or are not required. The test software aims to verify that specialized implementations meet the specification of the Level 3 BLAS and that implementations are correctly installed.},
journal = {ACM Trans. Math. Softw.},
month = {3},
pages = {18–28},
numpages = {11}
}

@inproceedings{mlir,
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 {{IEEE/ACM}} International Symposium on Code Generation and Optimization (CGO)},
  title={{{MLIR}}: Scaling Compiler Infrastructure for Domain Specific Computation},
  year={2021},
  volume={},
  number={},
  pages={2-14},
  doi={10.1109/CGO51591.2021.9370308}
}

@online{udaybondhugulaUsingMLIRHighPerformance2020,
  type = {Github Repository},
  title = {Using {{MLIR}} for {{High-Performance Code Gen}}: {{Part I}}},
  author = {{Uday Bondhugula}},
  date = {2020-03-02},
  url = {https://github.com/bondhugula/llvm-project/blob/hop/mlir/docs/HighPerfCodeGen.md},
  urldate = {2024-03-01},
  abstract = {The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Note: the repository does not accept github pull requests at this moment. Please submit your patches at...},
  langid = {english},
  organization = {{bondhugula/llvm-project}},
  file = {C:\Users\henri\Zotero\storage\KGMCKQ5P\HighPerfCodeGen.html}
}

@inproceedings{zukowskiSuperScalarRAMCPUCache2006,
  title = {Super-{{Scalar RAM-CPU Cache Compression}}},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{Data Engineering}}},
  author = {Zukowski, Marcin and Heman, Sandor and Nes, Niels and Boncz, Peter},
  date = {2006},
  series = {{{ICDE}} '06},
  pages = {59},
  publisher = {{IEEE Computer Society}},
  location = {{USA}},
  doi = {10.1109/ICDE.2006.150},
  url = {https://ir.cwi.nl/pub/10892},
  urldate = {2024-01-04},
  abstract = {High-performance data-intensive query processing tasks like OLAP, data mining or scientific data analysis can be severely I/O bound, even when high-end RAID storage systems are used. Compression can alleviate this bottleneck only if encoding and decoding speeds significantly exceed RAID I/O bandwidth. For this purpose, we propose three new versatile compression schemes (PDICT, PFOR, and PFOR-DELTA) that are specifically designed to extract maximum IPC from modern CPUs. We compare these algorithms with compression techniques used in (commercial) database and information retrieval systems. Our experiments on the MonetDB/X100 database system, using both DSM and PAX disk storage, show that these techniques strongly accelerate TPC-H performance to the point that the I/O bottleneck is eliminated.},
  isbn = {0-7695-2570-9},
  annotation = {[Author Manuscript]},
  file = {C:\Users\henri\Documents\WS23_24\LDE\References\SuperScalar.pdf}
}

@inproceedings{zukowskiVectorwiseVectorizedAnalytical2012,
  title = {Vectorwise: {{A Vectorized Analytical DBMS}}},
  shorttitle = {Vectorwise},
  booktitle = {2012 {{IEEE}} 28th {{International Conference}} on {{Data Engineering}}},
  author = {Zukowski, Marcin and Van De Wiel, Mark and Boncz, Peter},
  date = {2012-04},
  pages = {1349--1350},
  publisher = {{IEEE}},
  location = {{Arlington, VA, USA}},
  doi = {10.1109/ICDE.2012.148},
  url = {http://ieeexplore.ieee.org/document/6228203/},
  urldate = {2023-12-31},
  eventtitle = {2012 {{IEEE International Conference}} on {{Data Engineering}} ({{ICDE}} 2012)},
  isbn = {978-0-7695-4747-3 978-1-4673-0042-1},
  file = {C:\Users\henri\Zotero\storage\8N68FH3H\Zukowski et al. - 2012 - Vectorwise A Vectorized Analytical DBMS.pdf}
}
